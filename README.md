# Sales Data Analysis with LlamaIndex and Pandas

This project demonstrates how to use LlamaIndex to perform natural language queries on a Pandas DataFrame. The `Llamaindex_Pandas_Query.ipynb` notebook loads a sales dataset, performs basic exploratory analysis, and then uses a `PandasQueryEngine` to answer questions about the data.

## Code Overview

The notebook performs the following steps:

1.  **Data Loading**: Sales data is loaded from a CSV file hosted on GitHub into a Pandas DataFrame.
2.  **Exploratory Analysis**: Basic checks are performed on the DataFrame to understand its structure, such as viewing the first few rows (`.head()`), getting information about data types and null values (`.info()`), and counting duplicate values.
3.  **LlamaIndex Setup**:
    *   Installs the necessary dependencies, including `llama-index` and the integration with the Groq language model.
    *   Configures `Settings.llm` to use the `llama-3.3-70b-versatile` model from Groq, using an API key.
4.  **Query Engine Creation**:
    *   A `PandasQueryEngine` is instantiated with the sales DataFrame. This query engine can translate natural language questions into executable Pandas code.
5.  **Executing Queries**:
    *   Several questions in Portuguese are asked to the `query_engine`, such as:
        *   "What is the most used payment method?"
        *   "Which product type has the highest quantity per branch?"
        *   "Which branch has the highest revenue?"
    *   The notebook iterates over a list of questions, printing each question and the answer generated by LlamaIndex.

## How to Run

1.  **Clone the repository (if applicable).**
2.  **Install the dependencies:**
    ```bash
    pip install pandas llama-index llama-index-experimental llama-index-llms-groq
    ```
3.  **Set up your Groq API key:**
    *   Get an API key from the [Groq console](https://console.groq.com/keys).
    *   Make sure the key is accessible in the environment where the notebook will be executed (the example uses Google Colab's `userdata`).
4.  **Run the `Llamaindex_Pandas_Query.ipynb` notebook.**

The goal is to show the simplicity and power of using LLMs to interact with and extract insights from tabular data without needing to manually write Pandas code for each query.
